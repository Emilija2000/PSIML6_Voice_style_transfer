{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbRAL3G7Bqd5"
   },
   "source": [
    "# Povezivanje sa drive-om i git-om\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "XmhcydPO3KhC",
    "outputId": "c9d5f7f7-f3a8-4eda-801d-503666637cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#spajam ga sa mojim drajvom gde su svi fajlovi\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MxEAIBKb3LPG",
    "outputId": "b4e94f22-bb34-497a-b382-3607435939e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/neural_style_transfer_audio\n"
     ]
    }
   ],
   "source": [
    "#tačna lokacija\n",
    "%cd \"drive/My Drive/neural_style_transfer_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bItbeTGM3ScB"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Emilija2000/PSIML6_Voice_style_transfer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PNhfUA8J3emP",
    "outputId": "a689bee8-5832-48a0-b8da-d5bf7ff65638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/neural_style_transfer_audio/PSIML6_Voice_style_transfer\n"
     ]
    }
   ],
   "source": [
    "%cd PSIML6_Voice_style_transfer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vtls204ta3ke",
    "outputId": "de36e75e-2ddc-4a9a-91fd-d80784940389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFHmLcwoCD3M"
   },
   "source": [
    "#Import svih potrebnih stvari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "PekGUW7i3a92",
    "outputId": "8e3d8047-eaff-47df-c9f5-68206e24ef77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.24.1\n",
      "Collecting torchaudio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/34/c651430dea231e382ddf2eb5773239bf4885d9528f640a4ef39b12894cb8/torchaudio-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 2.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.6.0+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio) (1.18.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio) (0.16.0)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-0.6.0\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub\n",
    "!pip install torchaudio\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lrHP9GZb3mbQ"
   },
   "outputs": [],
   "source": [
    "#ubacivanje nasih fajlova kao biblioteka\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Leo7Znz49un"
   },
   "outputs": [],
   "source": [
    "dataset = dataloader.AccentDataset('data/recordings/recordings','data/speakers_all.csv')\n",
    "print (dataset.__len__())\n",
    "vect,label = dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSHUXEDfCLLc"
   },
   "source": [
    "#Prekopiran ceo kod - isprobavanje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ck4D36cYk086"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "import scipy\n",
    "import scipy.signal\n",
    "from scipy.io import wavfile\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import librosa                    \n",
    "import librosa.display\n",
    "\n",
    "\n",
    "AudioSegment.converter = \"ffmpeg\"\n",
    "allowed_genres = [\"blues\",\"classical\",\"country\",\"disco\",\"hiphop\",\"metal\",\"pop\",\"reggae\",\"rock\"]\n",
    "\n",
    "def readAudio(mp3_path):\n",
    "    '''\n",
    "    Read audio file on location mp3_path using librosa and creates spectrogram\n",
    "    '''\n",
    "    y, sr = librosa.load(mp3_path)\n",
    "    melSpec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    melSpec_dB = librosa.power_to_db(melSpec, ref=np.max)\n",
    "    #librosa.display.specshow(melSpec_dB)\n",
    "    return melSpec_dB, sr\n",
    "\n",
    "def writeAudio(spectrogram, sample_rate, output_file_name):\n",
    "    '''\n",
    "    For given scipy spectrogram and sample_rate, write .wav audiofile\n",
    "    with the name output_file_name + '.wav'\n",
    "    '''\n",
    "    audio_signal = librosa.core.spectrum.griffinlim(spectrogram)\n",
    "    #print(audio_signal, audio_signal.shape)\n",
    "    # write output\n",
    "    file_name = output_file_name + '.wav'\n",
    "    scipy.io.wavfile.write(file_name, sample_rate, np.array(audio_signal, dtype=np.int16))\n",
    "\n",
    "def readSpectrogram(png_path):\n",
    "    '''\n",
    "    Reads png file and save spectrogram as a matrix\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "class MusicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, csv_path):\n",
    "        self.data_names = []    #mp3 file location and data label\n",
    "        self.data_names_onehot = [] #mp3 file location and onehot encoded data label\n",
    "        self.classes = [] #all classes (possible labels)\n",
    "        \n",
    "        with open(csv_path) as csvfile:\n",
    "            #start cvs reader\n",
    "            csv_reader = csv.reader(csvfile,delimiter=',')\n",
    "            next(csv_reader) #skip first row\n",
    "            for row in csv_reader:\n",
    "                if (row[59] in allowed_genres): \n",
    "                    mp3_path = os.path.join(path,row[59],row[0])\n",
    "                    self.data_names.append((mp3_path, row[59])) \n",
    "                    if (row[59] not in self.classes):\n",
    "                        self.classes.append(row[59])\n",
    "\n",
    "            #create onehot encoding for data labels\n",
    "            for data in self.data_names:\n",
    "                label = torch.zeros(len(self.classes)) \n",
    "                label[self.classes.index(data[1])] = 1\n",
    "                self.data_names_onehot.append((data[0],label))\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        #read audiofile\n",
    "        spect, sr = readAudio(self.data_names[index][0])\n",
    "\n",
    "        #get onehot encoded label\n",
    "        label_onehot = self.data_names_onehot[index][1]\n",
    "        label_onehot = torch.Tensor(label_onehot)\n",
    "        #label_onehot = label.type(torch.long)\n",
    "        #label_onehot = label.reshape(len(label),1,1)\n",
    "\n",
    "        #int encoding for classes\n",
    "        label = torch.argmax(label_onehot).item()\n",
    "\n",
    "        #reshape spectrogram to represent 1 channel\n",
    "        spect = spect[:,:1280]\n",
    "        spect = torch.Tensor(spect).reshape(1,spect.shape[0],spect.shape[1])\n",
    "\n",
    "        return spect, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "pdyqhMYU4Xl-",
    "outputId": "de425cfd-d466-4474-ef80-c1c787db574d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velicina dataseta je:  900\n",
      "torch.Size([1, 128, 1280])\n"
     ]
    }
   ],
   "source": [
    "#isprobavanje\n",
    "dataset = MusicDataset('Data/genres_original','Data/features_30_sec.csv')\n",
    "print('Velicina dataseta je: ',dataset.__len__())\n",
    "dat,label = dataset.__getitem__(1)\n",
    "print(dat.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bLf-TeHpspH"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3O2VpLKSXFO"
   },
   "source": [
    "#Model klasifikatora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9tJ5w5eSZzW"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, output_num):\n",
    "        super(Classifier,self).__init__()\n",
    "        modules = []\n",
    "\n",
    "        modules.append(nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = 2, stride = 2))\n",
    "        modules.append(nn.BatchNorm2d(8))\n",
    "        modules.append(nn.ReLU(inplace = True))\n",
    "\n",
    "        modules.append(nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 2, stride = 2))\n",
    "        modules.append(nn.BatchNorm2d(16))\n",
    "        modules.append(nn.ReLU(inplace = True))\n",
    "\n",
    "        modules.append(nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 2, stride = 2))\n",
    "        modules.append(nn.BatchNorm2d(32))\n",
    "        modules.append(nn.ReLU(inplace = True))\n",
    "\n",
    "        modules.append(nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 2, stride = 2))\n",
    "        modules.append(nn.BatchNorm2d(64))\n",
    "        modules.append(nn.ReLU(inplace = True))\n",
    "\n",
    "        modules.append(nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 2, stride = 2))\n",
    "        modules.append(nn.BatchNorm2d(128))\n",
    "        modules.append(nn.ReLU(inplace = True))\n",
    "\n",
    "\n",
    "        modules.append(nn.AdaptiveAvgPool2d(output_size = 1))\n",
    "\n",
    "\n",
    "        self.fc=nn.Linear(in_features=128,out_features=output_num,bias=True)\n",
    "\n",
    "        self.sequence = nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        y = self.sequence(x)\n",
    "        y=torch.flatten(y,start_dim=1)\n",
    "        y = self.fc(y)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQ8VGk6jYwCt"
   },
   "outputs": [],
   "source": [
    "#create classifier and move to device\n",
    "classifier = Classifier(len(dataset.classes))\n",
    "device = torch.device('cuda')\n",
    "classifier = classifier.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_-y8gAtdSi-"
   },
   "source": [
    "#Trening klasifikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIh7yHvVdVgx"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr = learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PiAiSM7udtP2"
   },
   "outputs": [],
   "source": [
    "# make train and valid splits\n",
    "import random\n",
    "random.seed(0)  # rng seed, set to 0 for reproducibility\n",
    "\n",
    "dataset_indices = list(range(len(dataset)))\n",
    "random.shuffle(dataset_indices)  # shuffle the indices before splitting (use random.shuffle)\n",
    "\n",
    "#split datasets\n",
    "train_split_indices = dataset_indices[:int(len(dataset_indices)*0.6)]  # get the training split indices\n",
    "valid_split_indices = dataset_indices[int(len(dataset_indices)*0.6):int(len(dataset_indices)*0.8)]  # get the validation split indices \n",
    "test_split_indices = dataset_indices[int(len(dataset_indices)*0.8):]\n",
    "\n",
    "train_subset_sampler = torch.utils.data.SubsetRandomSampler(train_split_indices)\n",
    "valid_subset_sampler = torch.utils.data.SubsetRandomSampler(valid_split_indices)\n",
    "test_subset_sampler = torch.utils.data.SubsetRandomSampler(test_split_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFul8SvYfWdf"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_workers = 0\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, sampler=train_subset_sampler, num_workers=num_workers, drop_last=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, sampler=valid_subset_sampler, num_workers=num_workers, drop_last=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=test_split_indices, num_workers=num_workers, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "8vVGO6g1gGs0",
    "outputId": "b3e6f3f9-60a9-4215-813b-24a8fe01b855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0   iter: 10   batch_loss: 0.618316650390625\n",
      "epoch: 0   iter: 20   batch_loss: 0.6006342172622681\n",
      "epoch: 0   iter: 30   batch_loss: 0.370353639125824\n",
      "epoch: 0   iter: 40   batch_loss: 0.49635010957717896\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    classifier.train()\n",
    "    \n",
    "    for i, (spect,label) in enumerate(train_dataloader):\n",
    "        spect = spect.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(spect)\n",
    "        #print(\"output=\",output,\" label=\",label)\n",
    "        loss = loss_func(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % (10) == 0:\n",
    "            print(f'epoch: {epoch}   iter: {i+1}   batch_loss: {loss}')\n",
    "            #print('output: ', output,' label: ',label)\n",
    "\n",
    "    classifier.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (spect,label) in valid_dataloader:\n",
    "            spect = spect.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = classifier(spect)\n",
    "\n",
    "            y_pred = torch.log_softmax(output,-1)  # convert logits (model outputs) to class probabilities\n",
    "\n",
    "            _ , predicted = torch.max(y_pred, 1)  # find the most probable class (use torch.max)\n",
    "\n",
    "            total+=label.size(0)\n",
    "            correct+= (predicted == label).sum()\n",
    "\n",
    "\n",
    "    validation_accuracy = 100 * float(correct)/total\n",
    "    print(f'epoch: {epoch}   validation accuracy: {validation_accuracy}%' )\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-vN5sgGLivX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
