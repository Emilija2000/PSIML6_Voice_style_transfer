{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbRAL3G7Bqd5",
        "colab_type": "text"
      },
      "source": [
        "# Povezivanje sa drive-om i git-om\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmhcydPO3KhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c9d5f7f7-f3a8-4eda-801d-503666637cfd"
      },
      "source": [
        "#spajam ga sa mojim drajvom gde su svi fajlovi\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxEAIBKb3LPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4e94f22-bb34-497a-b382-3607435939e3"
      },
      "source": [
        "#tačna lokacija\n",
        "%cd \"drive/My Drive/neural_style_transfer_audio\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/neural_style_transfer_audio\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bItbeTGM3ScB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/Emilija2000/PSIML6_Voice_style_transfer.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNhfUA8J3emP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a689bee8-5832-48a0-b8da-d5bf7ff65638"
      },
      "source": [
        "%cd PSIML6_Voice_style_transfer/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/neural_style_transfer_audio/PSIML6_Voice_style_transfer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtls204ta3ke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de36e75e-2ddc-4a9a-91fd-d80784940389"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFHmLcwoCD3M",
        "colab_type": "text"
      },
      "source": [
        "#Import svih potrebnih stvari"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PekGUW7i3a92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "8e3d8047-eaff-47df-c9f5-68206e24ef77"
      },
      "source": [
        "!pip install pydub\n",
        "!pip install torchaudio\n",
        "!pip install scipy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.24.1\n",
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/34/c651430dea231e382ddf2eb5773239bf4885d9528f640a4ef39b12894cb8/torchaudio-0.6.0-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchaudio) (0.16.0)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.6.0\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrHP9GZb3mbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ubacivanje nasih fajlova kao biblioteka\n",
        "import dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Leo7Znz49un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataloader.AccentDataset('data/recordings/recordings','data/speakers_all.csv')\n",
        "print (dataset.__len__())\n",
        "vect,label = dataset.__getitem__(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSHUXEDfCLLc",
        "colab_type": "text"
      },
      "source": [
        "#Prekopiran ceo kod - isprobavanje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck4D36cYk086",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import copy\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from os import path\n",
        "from pydub import AudioSegment\n",
        "import scipy\n",
        "import scipy.signal\n",
        "from scipy.io import wavfile\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import librosa                    \n",
        "import librosa.display\n",
        "\n",
        "\n",
        "AudioSegment.converter = \"ffmpeg\"\n",
        "allowed_genres = [\"blues\",\"classical\",\"country\",\"disco\",\"hiphop\",\"jazz\",\"metal\",\"pop\",\"reggae\",\"rock\"]\n",
        "\n",
        "def readAudio(mp3_path):\n",
        "    '''\n",
        "    Read audio file on location mp3_path using librosa and creates spectrogram\n",
        "    '''\n",
        "    y, sr = librosa.load(mp3_path)\n",
        "    melSpec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    melSpec_dB = librosa.power_to_db(melSpec, ref=np.max)\n",
        "    #librosa.display.specshow(melSpec_dB)\n",
        "    return melSpec_dB, sr\n",
        "\n",
        "def writeAudio(spectrogram, sample_rate, output_file_name):\n",
        "    '''\n",
        "    For given scipy spectrogram and sample_rate, write .wav audiofile\n",
        "    with the name output_file_name + '.wav'\n",
        "    '''\n",
        "    audio_signal = librosa.core.spectrum.griffinlim(spectrogram)\n",
        "    #print(audio_signal, audio_signal.shape)\n",
        "    # write output\n",
        "    file_name = output_file_name + '.wav'\n",
        "    scipy.io.wavfile.write(file_name, sample_rate, np.array(audio_signal, dtype=np.int16))\n",
        "\n",
        "def readSpectrogram(png_path):\n",
        "    '''\n",
        "    Reads png file and save spectrogram as a matrix\n",
        "    '''\n",
        "    pass\n",
        "\n",
        "class MusicDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, csv_path):\n",
        "        self.data_names = []    #mp3 file location and data label\n",
        "        self.data_names_onehot = [] #mp3 file location and onehot encoded data label\n",
        "        self.classes = [] #all classes (possible labels)\n",
        "        \n",
        "        with open(csv_path) as csvfile:\n",
        "            #start cvs reader\n",
        "            csv_reader = csv.reader(csvfile,delimiter=',')\n",
        "            next(csv_reader) #skip first row\n",
        "            for row in csv_reader:\n",
        "                if (row[59] in allowed_genres): \n",
        "                    mp3_path = os.path.join(path,row[59],row[0])\n",
        "                    self.data_names.append((mp3_path, row[59])) \n",
        "                    if (row[59] not in self.classes):\n",
        "                        self.classes.append(row[59])\n",
        "\n",
        "            #create onehot encoding for data labels\n",
        "            for data in self.data_names:\n",
        "                label = torch.zeros(len(self.classes)) \n",
        "                label[self.classes.index(data[1])] = 1\n",
        "                self.data_names_onehot.append((data[0],label))\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        #read audiofile\n",
        "        spect, sr = readAudio(self.data_names[index][0])\n",
        "\n",
        "        #get onehot encoded label\n",
        "        label_onehot = self.data_names_onehot[index][1]\n",
        "        label_onehot = torch.Tensor(label_onehot)\n",
        "        #label_onehot = label.type(torch.long)\n",
        "        #label_onehot = label.reshape(len(label),1,1)\n",
        "\n",
        "        #int encoding for classes\n",
        "        label = torch.argmax(label_onehot).item()\n",
        "\n",
        "        #reshape spectrogram to represent 1 channel\n",
        "        spect = spect[:,:1280]\n",
        "        spect = torch.Tensor(spect).reshape(1,spect.shape[0],spect.shape[1])\n",
        "\n",
        "        return spect, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_names)\n",
        "    "
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdyqhMYU4Xl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "de425cfd-d466-4474-ef80-c1c787db574d"
      },
      "source": [
        "#isprobavanje\n",
        "dataset = MusicDataset('Data/genres_original','Data/features_30_sec.csv')\n",
        "print('Velicina dataseta je: ',dataset.__len__())\n",
        "dat,label = dataset.__getitem__(1)\n",
        "print(dat.size())\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Velicina dataseta je:  1000\n",
            "torch.Size([1, 128, 1280])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bLf-TeHpspH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3O2VpLKSXFO",
        "colab_type": "text"
      },
      "source": [
        "#Model klasifikatora\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9tJ5w5eSZzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, output_num):\n",
        "        super(Classifier,self).__init__()\n",
        "        modules = []\n",
        "\n",
        "        modules.append(nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = 2, stride = 2))\n",
        "        modules.append(nn.BatchNorm2d(8))\n",
        "        modules.append(nn.ReLU(inplace = True))\n",
        "\n",
        "        modules.append(nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 2, stride = 2))\n",
        "        modules.append(nn.BatchNorm2d(16))\n",
        "        modules.append(nn.ReLU(inplace = True))\n",
        "\n",
        "        modules.append(nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 2, stride = 2))\n",
        "        modules.append(nn.BatchNorm2d(32))\n",
        "        modules.append(nn.ReLU(inplace = True))\n",
        "\n",
        "        modules.append(nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 2, stride = 2))\n",
        "        modules.append(nn.BatchNorm2d(64))\n",
        "        modules.append(nn.ReLU(inplace = True))\n",
        "\n",
        "        modules.append(nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 2, stride = 2))\n",
        "        modules.append(nn.BatchNorm2d(128))\n",
        "        modules.append(nn.ReLU(inplace = True))\n",
        "\n",
        "\n",
        "        modules.append(nn.AdaptiveAvgPool2d(output_size = 1))\n",
        "\n",
        "\n",
        "        self.fc=nn.Linear(in_features=128,out_features=output_num,bias=True)\n",
        "\n",
        "        self.sequence = nn.Sequential(*modules)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        y = self.sequence(x)\n",
        "        y=torch.flatten(y,start_dim=1)\n",
        "        y = self.fc(y)\n",
        "        return y\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ8VGk6jYwCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create classifier and move to device\n",
        "classifier = Classifier(len(dataset.classes))\n",
        "device = torch.device('cuda')\n",
        "classifier = classifier.cuda()"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_-y8gAtdSi-",
        "colab_type": "text"
      },
      "source": [
        "#Trening klasifikatora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIh7yHvVdVgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(classifier.parameters(), lr = learning_rate)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiAiSM7udtP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make train and valid splits\n",
        "import random\n",
        "random.seed(0)  # rng seed, set to 0 for reproducibility\n",
        "\n",
        "dataset_indices = list(range(len(dataset)))\n",
        "random.shuffle(dataset_indices)  # shuffle the indices before splitting (use random.shuffle)\n",
        "\n",
        "#split datasets\n",
        "train_split_indices = dataset_indices[:int(len(dataset_indices)*0.6)]  # get the training split indices\n",
        "valid_split_indices = dataset_indices[int(len(dataset_indices)*0.6):int(len(dataset_indices)*0.8)]  # get the validation split indices \n",
        "test_split_indices = dataset_indices[int(len(dataset_indices)*0.8):]\n",
        "\n",
        "train_subset_sampler = torch.utils.data.SubsetRandomSampler(train_split_indices)\n",
        "valid_subset_sampler = torch.utils.data.SubsetRandomSampler(valid_split_indices)\n",
        "test_subset_sampler = torch.utils.data.SubsetRandomSampler(test_split_indices)\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFul8SvYfWdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "num_workers = 0\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, sampler=train_subset_sampler, num_workers=num_workers, drop_last=True)\n",
        "valid_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, sampler=valid_subset_sampler, num_workers=num_workers, drop_last=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=test_split_indices, num_workers=num_workers, drop_last=True)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vVGO6g1gGs0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "outputId": "b3e6f3f9-60a9-4215-813b-24a8fe01b855"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    classifier.train()\n",
        "    \n",
        "    for i, (spect,label) in enumerate(train_dataloader):\n",
        "        spect = spect.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = classifier(spect)\n",
        "        #print(\"output=\",output,\" label=\",label)\n",
        "        loss = loss_func(output, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % (1) == 0:\n",
        "            print(f'epoch: {epoch}   iter: {i+1}   batch_loss: {loss}')\n",
        "            #print('output: ', output,' label: ',label)\n",
        "\n",
        "    classifier.eval()\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (spect,label) in valid_dataloader:\n",
        "            spect = spect.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            output = classifier(spect)\n",
        "\n",
        "            y_pred = torch.log_softmax(output,-1)  # convert logits (model outputs) to class probabilities\n",
        "\n",
        "            , predicted = torch.max(y_pred, 1)  # find the most probable class (use torch.max)\n",
        "\n",
        "            total+= y.size(0)\n",
        "            correct+= (int(predicted == y)).sum()\n",
        "\n",
        "\n",
        "    validation_accuracy = 100 * float(correct)/total\n",
        "    print(f'epoch: {epoch}   validation accuracy: {validation_accuracy}%' )\n",
        "\n",
        "\n",
        "        \n",
        "        "
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0   iter: 1   batch_loss: 1.5329313278198242\n",
            "epoch: 0   iter: 2   batch_loss: 1.577140212059021\n",
            "epoch: 0   iter: 3   batch_loss: 1.643634557723999\n",
            "epoch: 0   iter: 4   batch_loss: 1.9305698871612549\n",
            "epoch: 0   iter: 5   batch_loss: 1.9317677021026611\n",
            "epoch: 0   iter: 6   batch_loss: 1.9223048686981201\n",
            "epoch: 0   iter: 7   batch_loss: 1.8988357782363892\n",
            "epoch: 0   iter: 8   batch_loss: 1.50393807888031\n",
            "epoch: 0   iter: 9   batch_loss: 1.8164136409759521\n",
            "epoch: 0   iter: 10   batch_loss: 1.792891502380371\n",
            "epoch: 0   iter: 11   batch_loss: 1.495210886001587\n",
            "epoch: 0   iter: 12   batch_loss: 1.6918067932128906\n",
            "epoch: 0   iter: 13   batch_loss: 1.874091386795044\n",
            "epoch: 0   iter: 14   batch_loss: 1.8176500797271729\n",
            "epoch: 0   iter: 15   batch_loss: 1.9528436660766602\n",
            "epoch: 0   iter: 16   batch_loss: 1.7618160247802734\n",
            "epoch: 0   iter: 17   batch_loss: 1.636839509010315\n",
            "epoch: 0   iter: 18   batch_loss: 1.4146817922592163\n",
            "epoch: 0   iter: 19   batch_loss: 1.626970887184143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-3e351b494d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-5e4f4665a8d8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m#read audiofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mspect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m#get onehot encoded label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-111-5e4f4665a8d8>\u001b[0m in \u001b[0;36mreadAudio\u001b[0;34m(mp3_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mRead\u001b[0m \u001b[0maudio\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mon\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0mmp3_path\u001b[0m \u001b[0musing\u001b[0m \u001b[0mlibrosa\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0mspectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     '''\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp3_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mmelSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmelSpec_dB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelSpec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mrealpath\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    393\u001b[0m symbolic links encountered in the path.\"\"\"\n\u001b[1;32m    394\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_joinrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36m_joinrealpath\u001b[0;34m(path, rest, seen)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mislink\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;34m\"\"\"Test whether a path is a symbolic link\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-vN5sgGLivX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}